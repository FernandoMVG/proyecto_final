version: "3.9"
services:
  llama-app:
    image: modulo_llm_cpu
    build:
      context: .
      dockerfile: Dockerfile
    container_name: contenedor_modulo_llm_cpu
    ports:
      - "8080:8080"
    volumes:
      - ./models:/app/models
      - ./output:/app/output
    env_file:
      - .env 
    environment:
      - LOG_LEVEL=INFO
    # Si tu código espera otros archivos, agrega más volumenes aquí

# Notas:
# - Para que docker-compose detecte la GPU, necesitas Docker >= 19.03 y el NVIDIA Container Toolkit instalado.
# - Si usas simplemente "docker compose up", usa el nombre de imagen que hayas construido o déjalo a build.